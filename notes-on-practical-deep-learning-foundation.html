<!DOCTYPE html><html lang="en-gb"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Notes on &quot;Practical deep learning&quot;: foundation - Turkmenson</title><meta name="description" content="While trying to launch the model, I discovered the book was outdated. Now, we took video lessons more than the book chapters. These are the notes on Lesson 3: How Neural Networks work and how to optimize it. Run notebooks in the /clean folder from the&hellip;"><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://turkmenson.com/notes-on-practical-deep-learning-foundation.html"><link rel="alternate" type="application/atom+xml" href="https://turkmenson.com/feed.xml"><link rel="alternate" type="application/json" href="https://turkmenson.com/feed.json"><meta property="og:title" content="Notes on 'Practical deep learning': foundation"><meta property="og:image" content="https://turkmenson.com/media/website/ahmetson.png"><meta property="og:image:width" content="176"><meta property="og:image:height" content="176"><meta property="og:site_name" content="Turkmenson"><meta property="og:description" content="While trying to launch the model, I discovered the book was outdated. Now, we took video lessons more than the book chapters. These are the notes on Lesson 3: How Neural Networks work and how to optimize it. Run notebooks in the /clean folder from the&hellip;"><meta property="og:url" content="https://turkmenson.com/notes-on-practical-deep-learning-foundation.html"><meta property="og:type" content="article"><link rel="stylesheet" href="https://turkmenson.com/assets/css/style.css?v=98f7ea838539e6639bc1360c5e4ff565"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://turkmenson.com/notes-on-practical-deep-learning-foundation.html"},"headline":"Notes on \"Practical deep learning\": foundation","datePublished":"2023-12-28T22:50","dateModified":"2023-12-29T00:29","image":{"@type":"ImageObject","url":"https://turkmenson.com/media/website/ahmetson.png","height":176,"width":176},"description":"While trying to launch the model, I discovered the book was outdated. Now, we took video lessons more than the book chapters. These are the notes on Lesson 3: How Neural Networks work and how to optimize it. Run notebooks in the /clean folder from the&hellip;","author":{"@type":"Person","name":"Medet Ahmetson","url":"https://turkmenson.com/authors/medet-ahmetson/"},"publisher":{"@type":"Organization","name":"Medet Ahmetson","logo":{"@type":"ImageObject","url":"https://turkmenson.com/media/website/ahmetson.png","height":176,"width":176}}}</script><noscript><style>img[loading] {
                    opacity: 1;
                }</style></noscript></head><body><div class="site-container"><header class="top" id="js-header"><a class="logo" href="https://turkmenson.com/"><img src="https://turkmenson.com/media/website/ahmetson.png" alt="Turkmenson" width="176" height="176"></a><nav class="navbar js-navbar"><button class="navbar__toggle js-toggle" aria-label="Menu" aria-haspopup="true" aria-expanded="false"><span class="navbar__toggle-box"><span class="navbar__toggle-inner">Menu</span></span></button><ul class="navbar__menu"><li><a href="https://turkmenson.com/tags/god/" title="All my worries I share with God" target="_self">God</a></li><li class="has-submenu"><a href="https://turkmenson.com/tags/people/" title="People and history" target="_self" aria-haspopup="true">People</a><ul class="navbar__submenu level-2" aria-hidden="true"><li><a href="https://turkmenson.com/tags/turkmen/" title="My thoughts related to Turkmenians" target="_self">Turkmenians</a></li><li class="has-submenu"><a href="https://turkmenson.com/tags/history/" title="Historical notes" target="_self" aria-haspopup="true">History</a><ul class="navbar__submenu level-3" aria-hidden="true"><li><a href="https://turkmenson.com/tags/seljuk/" title="All related to the Seljuk Empire" target="_self">Seljuk Empire</a></li></ul></li><li><a href="https://turkmenson.com/tags/persona/" target="_self">Persona</a></li><li><a href="https://turkmenson.com/tags/me/" target="_self">Medet Ahmetson</a></li></ul></li><li class="has-submenu"><span class="is-separator" title="Ideas and projects" aria-haspopup="true">Projects</span><ul class="navbar__submenu level-2" aria-hidden="true"><li class="has-submenu"><span class="is-separator" title="A secure random number generator for blockchains" aria-haspopup="true">RNG for blockchains</span><ul class="navbar__submenu level-3" aria-hidden="true"><li><a href="https://github.com/ahmetson/rng" target="_blank">Github</a></li><li><a href="https://turkmenson.com/rnb-blockchain-whitepaper.html" target="_self">Whitepaper</a></li></ul></li><li><a href="https://turkmenson.com/archived-projects.html" target="_self">Archived projects</a></li><li><a href="https://turkmenson.com/tags/game/" target="_self">Games</a></li><li><a href="https://turkmenson.com/tags/programming-language-by-ahmetson/" target="_self">Programming Languages</a></li><li><a href="https://turkmenson.com/tags/manva-chat/" target="_self">Manva Chat</a></li><li><a href="https://turkmenson.com/tags/ara/" target="_self">Ara</a></li></ul></li><li class="has-submenu"><a href="https://turkmenson.com/tags/technology/" target="_self" aria-haspopup="true">Technology</a><ul class="navbar__submenu level-2" aria-hidden="true"><li class="has-submenu"><a href="https://turkmenson.com/tags/blockchain/" target="_self" aria-haspopup="true">Blockchain</a><ul class="navbar__submenu level-3" aria-hidden="true"><li><a href="https://turkmenson.com/tags/blockchain-review/" target="_self">Review</a></li><li><a href="https://turkmenson.com/tags/cosmos-sdk/" target="_self">Cosmos SDK</a></li></ul></li><li class="has-submenu"><a href="https://turkmenson.com/tags/ai/" target="_self" aria-haspopup="true">AI</a><ul class="navbar__submenu level-3" aria-hidden="true"><li><a href="https://turkmenson.com/tags/ai-notes/" target="_self">Practical Deep Learning for Coders</a></li></ul></li><li><a href="https://turkmenson.com/tags/programming-language/" target="_self">Programming Language</a></li></ul></li></ul></nav></header><main><article class="post"><div class="hero"><header class="hero__content"><div class="wrapper"><div class="post__meta"><time datetime="2023-12-28T22:50">28 Dec 2023</time></div><h1>Notes on &quot;Practical deep learning&quot;: foundation</h1><div class="post__meta post__meta--author"><a href="https://turkmenson.com/authors/medet-ahmetson/" class="feed__author">Medet Ahmetson</a></div></div></header></div><div class="wrapper post__entry"><p class="msg msg--highlight msg--warning">While trying to launch the model, I discovered the book was outdated. Now, we took video lessons more than the book chapters.</p><p>These are the notes on Lesson 3: How Neural Networks work and how to optimize it.</p><h2>How to learn?</h2><ol><li>Watch the lessons</li><li>(Read the chapters)</li><li>Run notebooks and experiment.</li><li>Reproduce results</li><li>Repeat with different dataset</li></ol><p class="msg--info msg--highlight msg">Run notebooks in the <a href="https://github.com/fastai/fastbook/tree/master/clean" target="_blank" rel="noopener noreferrer">/clean</a> folder from the book repo.</p><h2>About exported model</h2><p>The exported model '.pkl' has two things.</p><ol><li>Preprocessing steps to turn data into a model: <code>DataLoader</code>part.</li><li>Trained model available in <code>.model</code>parameter. It's a tree of multiple models for each neural layer. The submodules are available by <code>model.get_submodule()</code>method.</li></ol><p class="msg msg--highlight">@interact(a=1, b=2, c=3) is the particular keyword for jupyter to make interactive parameters.</p><h1>How does Neural Network work?</h1><p>A neural network tries to fit a function to data. The neural network adjusts the function parameters until the function's output is not close to the data.</p><p>After adjusting the parameter, a loss function is used to see how close the function output is to the data. The <code>mean_mean_error: ((output - data)^2).mean()</code>is the most popular loss function.</p><p>To automate adjustment by a loss function, we could calculate the derivative. Derivative checks how much parameter value increase increases the output. And how far it is from the data. The distance from the data to the function output is called a <code>slope</code> or <code>gradient</code>.</p><p class="msg msg--highlight">Python tip: <code>func(*params)</code>. The * expands the parameters into function arguments as a, b, and c.</p><p>The <code>PyTorch</code> library has built-in derivative calculating functions. This function is called a <code>tensor.backward()</code>. It's the method of the tensors.</p><p>How to enable derivative:</p><ol><li>Create a tensor: <code>abc = torch.tensor([1.5, 1.5, 1.5])</code> . For example, it created a rank one tensor.</li><li>Enable derivative calculation in the tensor: <code>abs.requires_grad_()</code>.</li><li>Calculate loss. Then, calculate a derivative using <code>.backward()</code>. This function adds the <code>.grad</code> property to the tensor with the slope derivative.</li></ol><p>Once the gradient value is available, we can iterate multiple times by adjusting parameters by the slope number.</p><p>This loop is called <strong>optimization</strong>, which means decreasing the loss value.</p><h2>Example</h2><p>Assume we have random dots on the graph for the <em>c*x^2 + b*x + a </em>equation. Let the function find the values for <em>a, b,</em> and <em>c</em>. </p><p>We have multiple dots for each part, not one. Because if there was one dot, we could draw a line by them.</p><p>Initially, we picked some random numbers as the starting point. Then, we calculate the loss using <code>mean_square_error</code>by passing random dots and our initial values.</p><p>Assume that the numbers are converted into tensors with enabled derivatives. Finally, we adjust the values until the gradient doesn't decrease sufficiently.</p><h2>ReLu</h2><p><strong>Relu</strong> is a short name for <strong>Rectified Linear:</strong></p><p><code>def rectified_linear(m, b, x):<br>  y = m * x + b<br>  return torch.clip(y, 0.)</code></p><p>This function is the single function whose negative value is turned into 0.</p><p>Combining multiple relationships creates a flexible function that can solve almost any problem. </p><p>This is pretty much the foundation on which all neural networks are built.</p></div><footer class="wrapper post__footer"><p class="post__last-updated">This article was updated on 29 Dec 2023</p><ul class="post__tag"><li><a href="https://turkmenson.com/tags/ai/">ai</a></li><li><a href="https://turkmenson.com/tags/ai-notes/">ai-notes</a></li><li><a href="https://turkmenson.com/tags/technology/">technology</a></li></ul><div class="post__share"></div><div class="post__bio bio"><div><h3 class="bio__name"><a href="https://turkmenson.com/authors/medet-ahmetson/" rel="author">Medet Ahmetson</a></h3></div></div></footer></article><nav class="post__nav"><div class="post__nav-inner"><div class="post__nav-prev"><svg width="1.041em" height="0.416em" aria-hidden="true"><use xlink:href="https://turkmenson.com/assets/svg/svg-map.svg#arrow-prev"/></svg> <a href="https://turkmenson.com/openzeppelin-in-preda-programming-language.html" class="post__nav-link" rel="prev"><span>Previous</span> OpenZeppelin in Preda programming language</a></div><div class="post__nav-next"><a href="https://turkmenson.com/programming-language-rust.html" class="post__nav-link" rel="next"><span>Next</span> Programming Language: Rust </a><svg width="1.041em" height="0.416em" aria-hidden="true"><use xlink:href="https://turkmenson.com/assets/svg/svg-map.svg#arrow-next"/></svg></div></div></nav><div class="post__related related"><div class="wrapper"><h2 class="h5 related__title">You should also read:</h2><article class="related__item"><div class="feed__meta"><time datetime="2023-12-22T16:41" class="feed__date">22 Dec 2023</time></div><h3 class="h1"><a href="https://turkmenson.com/notes-on-practical-deep-learning-launching.html">Notes on &quot;Practical deep learning&quot;: launching</a></h3></article><article class="related__item"><div class="feed__meta"><time datetime="2023-12-21T16:38" class="feed__date">21 Dec 2023</time></div><h3 class="h1"><a href="https://turkmenson.com/notes-on-practical-deep-learning-for-coders.html">Notes on &quot;Practical Deep Learning for Coders&quot;</a></h3></article></div></div></main><footer class="footer"><div class="footer__copyright"><p>2023 Medet Ahmetson</p></div><button onclick="backToTopFunction()" id="backToTop" class="footer__bttop" aria-label="Back to top" title="Back to top"><svg><use xlink:href="https://turkmenson.com/assets/svg/svg-map.svg#toparrow"/></svg></button></footer></div><script defer="defer" src="https://turkmenson.com/assets/js/scripts.min.js?v=f47c11534595205f20935f0db2a62a85"></script><script>window.publiiThemeMenuConfig={mobileMenuMode:'sidebar',animationSpeed:300,submenuWidth: 'auto',doubleClickTime:500,mobileMenuExpandableSubmenus:true,relatedContainerForOverlayMenuSelector:'.top'};</script><script>var images = document.querySelectorAll('img[loading]');
        for (var i = 0; i < images.length; i++) {
            if (images[i].complete) {
                images[i].classList.add('is-loaded');
            } else {
                images[i].addEventListener('load', function () {
                    this.classList.add('is-loaded');
                }, false);
            }
        }</script></body></html>